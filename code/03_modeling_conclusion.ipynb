{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624e4927-0766-42aa-8835-7991119ae164",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13589a01-a8c1-43a4-8a7f-6e32c09e9216",
   "metadata": {},
   "source": [
    "##### During lab 3.01 I observed a potential correlation between squarefeet and price. This to me is a natural occurrence because property represented as area represents the non-depreciative asset of land ownership. Addtionally, having many conversations with Bede, there became a focus on the relationships between quality/conditon and salesprice.\n",
    "\n",
    "##### This raises the question: Are descriptors of depreciation (quality/cond) better estimators of sales price than descriptors of value (property size by sqft)? \n",
    "\n",
    "#### H0: The true mean difference in RMSE between models who have more Qual/Cond features than those who do not is 0. \n",
    "\n",
    "#### H1: The true mean difference in RMSE between models who have more Qual/Cond features than those who do not is NOT 0. \n",
    "\n",
    "> $H_0: \\mu_\\text{trl_RMSE} - \\mu_\\text{ctrl_RMSE} = 0$ <br>\n",
    "> $H_A: \\mu_\\text{trt_RMSE} - \\mu_\\text{ctrl_RMSE}\\ne0$ <br>\n",
    "### $$P(\\text{data}\\;|\\;H_0 \\text{ true})$$\n",
    "$$\\alpha=0.05$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7a7e0-faff-48d6-b046-4d6c5d1504b2",
   "metadata": {},
   "source": [
    "Additional Experiment Information:\n",
    "- To get the mean RMSE score for the two different kinds of models, we will run each model structure 3 times with the same 3 random_states on the test train split\n",
    "- List of Random States used: [777, 42, 1]\n",
    "- After each run, record different measurements and then calculate if the difference of mean RMSE beats the significant factor or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83139377-c9e4-4c49-b408-f7b5c293b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operating system\n",
    "import os\n",
    "# package settings\n",
    "from sklearn import set_config\n",
    "# Data Manip & View\n",
    "import pandas as pd\n",
    "# Data Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# modeling process\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# additional\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1665ba78-17d1-4e48-83aa-5dbdb38b4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set transformers to output as pandas dfs\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4cedc-372a-4013-814c-7348b5978b56",
   "metadata": {},
   "source": [
    "### Now that we have a better understanding of the data we are working with let's do some preprocessing and feature engineering before making our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6792ad6-eda9-4722-ae5b-dd03d4d2e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in datasets\n",
    "df_train = pd.read_csv('../datasets/cleaned_datasets/cleaned_train.csv', index_col=0)\n",
    "df_test = pd.read_csv('../datasets/cleaned_datasets/cleaned_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e1c214a-db63-4c63-ad4a-7e2cfaf7323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set original dataframe index for future use\n",
    "train_id = df_train['id']\n",
    "test_id = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d75cd01-0c15-4c16-b9bd-1e9c0c7f039f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2051, 77), (878, 76))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine shape\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8702e84-69c2-4387-98ac-7b1ebc0e5eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate dataframes for features we are interested in hypothesis wise\n",
    "# however as we saw in EDA, we'll probably need to pull in some of these features\n",
    "# to help boost our model's performance\n",
    "\n",
    "df_train_hyp = df_train.drop(columns = ['pid','ms_subclass','year_built','year_remod/add','bsmt_full_bath',\n",
    "                                        'bsmt_half_bath','full_bath','half_bath','bedroom_abvgr','kitchen_abvgr',\n",
    "                                        'totrms_abvgrd','fireplaces','garage_yr_blt','garage_cars','enclosed_porch',\n",
    "                                        '3ssn_porch','screen_porch','misc_val','mo_sold','yr_sold','ms_zoning',\n",
    "                                        'street','lot_shape','land_contour','utilities','lot_config','land_slope',\n",
    "                                        'neighborhood','condition_1','condition_2','bldg_type','house_style',\n",
    "                                        'roof_style','roof_matl','exterior_1st','exterior_2nd','mas_vnr_type',\n",
    "                                        'foundation','bsmt_exposure','bsmtfin_type_1','bsmtfin_type_2','heating',\n",
    "                                        'central_air','electrical','functional','garage_type','garage_finish',\n",
    "                                        'paved_drive','sale_type'])\n",
    "\n",
    "df_test_hyp = df_test.drop(columns = ['pid','ms_subclass','year_built','year_remod/add','bsmt_full_bath',\n",
    "                                        'bsmt_half_bath','full_bath','half_bath','bedroom_abvgr','kitchen_abvgr',\n",
    "                                        'totrms_abvgrd','fireplaces','garage_yr_blt','garage_cars','enclosed_porch',\n",
    "                                        '3ssn_porch','screen_porch','misc_val','mo_sold','yr_sold','ms_zoning',\n",
    "                                        'street','lot_shape','land_contour','utilities','lot_config','land_slope',\n",
    "                                        'neighborhood','condition_1','condition_2','bldg_type','house_style',\n",
    "                                        'roof_style','roof_matl','exterior_1st','exterior_2nd','mas_vnr_type',\n",
    "                                        'foundation','bsmt_exposure','bsmtfin_type_1','bsmtfin_type_2','heating',\n",
    "                                        'central_air','electrical','functional','garage_type','garage_finish',\n",
    "                                        'paved_drive','sale_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29abe3b3-77e7-42a4-a396-c65db83c7f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2051, 28), (878, 27))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test shape of new hypothesis model dfs\n",
    "df_train_hyp.shape, df_test_hyp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cda345e6-a276-4a56-ac5a-481ef4964fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dfs into their numerical and object forms for OHE\n",
    "df_train_hyp_num = df_train_hyp.select_dtypes('number')\n",
    "df_train_hyp_obj = df_train_hyp.select_dtypes('object')\n",
    "df_test_hyp_num = df_test_hyp.select_dtypes('number')\n",
    "df_test_hyp_obj = df_test_hyp.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ebdf7b6-b74b-40a8-8342-60c7022750fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is train num (2051, 19)\n",
      "this is train ob (2051, 9)\n",
      "this is test num (878, 18)\n",
      "this is test ob (878, 9)\n"
     ]
    }
   ],
   "source": [
    "# Check for symmetry\n",
    "print('this is train num', df_train_hyp_num.shape)\n",
    "print('this is train ob', df_train_hyp_obj.shape)\n",
    "print('this is test num', df_test_hyp_num.shape)\n",
    "print('this is test ob', df_test_hyp_obj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da68bbf7-356d-42b7-9ece-535fb1fa938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate OneHotEncoder for Categorical Features, dropping first row to apply inference to data set\n",
    "ohe = OneHotEncoder(\n",
    "    drop='first',\n",
    "    sparse=False,\n",
    "    handle_unknown='ignore'\n",
    ")\n",
    "\n",
    "# Instantiate StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Instantiate PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree = 2,\n",
    "                          interaction_only = True,\n",
    "                          include_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e0fc3-8fa6-4233-a6ce-964ba362e8ea",
   "metadata": {},
   "source": [
    "# Model 1:\n",
    "- All Hypothesis Features despite multicolinearity\n",
    "- OHE, SS, and Polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30313deb-0827-4673-a1f4-619ccf249525",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "650a364a-eef8-4da7-8b33-82d1397aa35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Transform Train Set\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    df_train_hyp_obj = ohe.fit_transform(df_train_hyp_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7fe5d73-bb9c-412d-8626-07f6b139a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Test Set\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    df_test_hyp_obj = ohe.transform(df_test_hyp_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "135925da-a0ba-41a2-a055-13d74dfa7ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add index back to object for merge using saved indexes\n",
    "df_train_hyp_obj['id'] = train_id\n",
    "df_test_hyp_obj['id'] = test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2ca7e23-6714-4dee-b767-ae3c50b30a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge respective dfs back together for \n",
    "df_ohe_train = df_train_hyp_num.merge(df_train_hyp_obj, how='left', on='id')\n",
    "df_ohe_test = df_test_hyp_num.merge(df_test_hyp_obj, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa6f9de8-2e8e-496e-9993-be9331a952de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2051, 54), (878, 53))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Shapes after OHE\n",
    "df_ohe_train.shape,df_ohe_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03921e68-1efd-43ac-93bb-8c28f22f7230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our X and Y\n",
    "X = df_ohe_train.drop(columns=['saleprice'])\n",
    "y = df_ohe_train['saleprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c651d5d-fd7b-4738-91fe-2a24c1b804c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Train Split, with different Random States to get mean RMSE for hypothesis\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25783e26-c16e-4f67-ad56-d8c1593b6194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1538, 53), (513, 53), (1538,), (513,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bef61c-ff97-4422-87c4-c520cc345346",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1e707-a8d1-4ead-82e8-520feeb22501",
   "metadata": {},
   "source": [
    "### Poly - Increase number of Features by combining interactions only (ex. a*b, but not a**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2ab387f-4cad-4436-b81c-d834e07fad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly = poly.fit_transform(X_train.drop(columns=['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f2b1d9b-2de7-4789-b971-11ae56bc8f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1538, 1378)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0e32df5-347f-40b2-8a59-dc4d51798474",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_poly = poly.transform(X_test.drop(columns=['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0c160da-a9ec-4d28-94be-2bcf22c67b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 1378)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654ceac-3c7d-46cd-b78a-a5f3b530659a",
   "metadata": {},
   "source": [
    "### Standard Scaler - Transform all numerical data points to be on the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "526d65c5-b289-4e0e-8a6c-f571cf524c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss = ss.fit_transform(X_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89765556-1760-4989-8c32-48706c79a5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1538, 1378)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "174e775f-78e5-4a6e-a96b-64ede2f69d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ss = ss.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc37d516-31ef-4200-9f7b-a129cd67df9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 1378)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_ss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fafb29-ebf3-4191-a740-30c5b5c57b9e",
   "metadata": {},
   "source": [
    "### Baseline Model - Plot the mean of y to better understand our future model's perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "990a42f2-9cf3-4941-803a-eb45eba2b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_1 = [y_train.mean()]*len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3460d0a4-9133-4c2c-9e0a-545ba6a17f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00018676221445179664"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, base_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a86a44-3fde-46ac-9e4f-c1b03fe765e9",
   "metadata": {},
   "source": [
    "#### Looking at our Baseline model for the first go around, we can't do much worse than it. As the baseline is only the mean of the y it is heavily underfit to the data and therefore negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98785a-dfb8-4333-a9a7-9016a7c4d165",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15745d77-4608-4e55-8158-ce997b97de17",
   "metadata": {},
   "source": [
    "Multi Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46a85242-4a1c-4bb8-a36e-d04d6af0ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33dbf820-a56b-439d-9fd6-99311590c449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Model\n",
    "lr.fit(X_train_ss, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4145c-8943-47f9-802e-0a4fd8f85282",
   "metadata": {},
   "source": [
    "Calculate R2 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3fb7ca54-5b54-4fbd-9b95-ab9fa8d6a1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9592892516217444"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train_ss, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a319445-8ecf-4a88-a270-0e55148a1efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.623684659803418e+29"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_ss, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79961cac-ceba-4605-a932-06449d42d2e1",
   "metadata": {},
   "source": [
    "Calculate RMSE on both Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a506c3a0-7c18-40fa-bf40-6f4a0e74aa8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15946.81406768557"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, lr.predict(X_train_ss), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd565c60-07fb-4b51-b1f9-739534b325eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.806328309389104e+19"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, lr.predict(X_test_ss), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa7e71d7-6987-4fac-b5a1-90ae74507d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 181148.55005653374\n",
      "coeficient: [ 2.13723530e+17  2.45550005e+15 -7.90341939e+15 ...  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(f'intercept: {lr.intercept_}')\n",
    "print(f'coeficient: {lr.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d75fb-1859-4692-a0ef-76ad543be86f",
   "metadata": {},
   "source": [
    "Based on our Intercepts and coefficients, when x = 0 our base price is ~181,148.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f269cbc7-eb74-47c9-b245-eb82a9d8e273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8116405776931652"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X_train, y_train, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eecdc9-1f79-4499-b13b-8386fe70aa26",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- ##### Our first model is very overfit to our training data with a lot of bias\n",
    "- ##### There is also a lot of variance as well with our test score above the billions in RMSE\n",
    "- ##### However when we cross val score our train data, our score isnt too bad? It suggests that with a cv split of 5, that we can generalise 85% over the whole dataset\n",
    "- ##### Before we move on to creating our hypothesis models and testing our hypothesis, let's see if Ridge, Lasso, and ElasticNet can help this original model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75691ae-00a5-4fd4-bf00-9dce3ace1df1",
   "metadata": {},
   "source": [
    "### CV Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "98570364-0d99-4c44-b926-1ca8a1a667fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-10, 5, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fddf732-1dae-4423-b19f-485bcac46d1e",
   "metadata": {},
   "source": [
    "### LinearRegression - RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "52eab8cc-4e0f-439c-a33c-2e519fa0b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_cv = RidgeCV(alphas=alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ab6e6648-255d-43a1-a060-3375e18ba46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    rg_cv.fit(X_train_ss, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ec41c892-f885-4355-b6ff-8d6d3faa994c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392.631340170684"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Alpha\n",
    "rg_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4797d7fa-8a39-41ae-b563-585f9b4cfdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training r2: 0.9335206571091633\n",
      "validation r2: 0.8715290300505348\n",
      "cross val score: 0.7923631732709664\n",
      "\n",
      "training RMSE: 20378.055776621502\n",
      "validation RMSE: 28618.095982381557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "training r2: {rg_cv.score(X_train_ss, y_train)}\n",
    "validation r2: {rg_cv.score(X_test_ss, y_test)}\n",
    "cross val score: {cross_val_score(RidgeCV(alphas = rg_cv.alpha_), X_train_ss, y_train).mean()}\n",
    "\n",
    "training RMSE: {mean_squared_error(y_train, rg_cv.predict(X_train_ss), squared=False)}\n",
    "validation RMSE: {mean_squared_error(y_test, rg_cv.predict(X_test_ss), squared=False)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b882b0de-fc2e-43c5-82bb-ce34295268c6",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- #### Ridge definitely made a big improvment on model performance over mlr; bringing our R2 scores on training and test much closer to each other but still exhibiting an overfit model with a lot of bias and variance. \n",
    "- #### Our RMSE is also in a much better place, while still experience a large amount of variance\n",
    "- #### Will be interesting to see how much better Ridge performs when we are more selective with what features we include in regards to multicolinearity seen in our EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e430d63-9ebd-4f11-bb5b-db307cdf956e",
   "metadata": {},
   "source": [
    "### LinearRegression - LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "82e6fd80-4eb6-4d66-9f95-3896a77c0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_alphas = np.arange(0, 1, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c7780276-c0a6-4d01-8ef0-dc20c3fefbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_cv = LassoCV(alphas=l_alphas, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "636f607b-46cb-41bc-a91b-671741e17036",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    ls_cv.fit(X_train_ss, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "05aa4e57-8624-45dc-b279-62ea52057733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8200000000000001"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "825f02c5-e00a-45ed-bb8f-17518686ec49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter('ignore')\n",
    "    \n",
    "#     ls_cv.fit(X_train_ss, y_train)\n",
    "#     print(f\"\"\"\n",
    "#     training r2: {ls_cv.score(X_train_ss, y_train)}\n",
    "#     validation r2: {ls_cv.score(X_test_ss, y_test)}\n",
    "#     cross val score: {cross_val_score(LassoCV(alphas = alphas, n_jobs=-1), X_train_ss, y_train).mean()}\n",
    "\n",
    "#     training RMSE: {mean_squared_error(y_train, ls_cv.predict(X_train_ss), squared=False)}\n",
    "#     validation RMSE: {mean_squared_error(y_test, ls_cv.predict(X_test_ss), squared=False)}\n",
    "#     \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892532c-3797-45d1-bab4-eb4b7999c20b",
   "metadata": {},
   "source": [
    "The model is not well defined in that we cannot complete an actual LassoCV Model, let's see if ElasticNetCV can finish scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d7b6f-172b-4812-a1b4-b1b7f5ea92ed",
   "metadata": {},
   "source": [
    "### LinearRegression - ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0b92e682-6c6b-461c-af20-e47898e4d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate ElasticNetCV\n",
    "enet_cv = ElasticNetCV(\n",
    "    l1_ratio = [.04, .05, .06, .07],\n",
    "    alphas = np.logspace(-10, 5, 200),\n",
    "    cv = 5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Instantiate ElasticNetCV\n",
    "enet_cv1 = ElasticNetCV(\n",
    "    l1_ratio = [.04, .05, .06, .07],\n",
    "    alphas = np.logspace(-10, 5, 200),\n",
    "    cv = 5,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830f5c6f-4489-4476-b8c5-a4e1b008eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter('ignore')\n",
    "    \n",
    "#     enet_cv.fit(X_train_ss, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d22cde-d50b-4e27-9e71-43ed67ab58bd",
   "metadata": {},
   "source": [
    "Similar to our LassoCV run, this model with all the features we are interested in is not well defined. Possible explanations as to why both LassoCv and ElasticNetCV failed was because of the multicollinearity present in our dataset affecting the gradient and causing a convergence to never appear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16d1de-cbf8-462a-b7c7-cabddd1cd78d",
   "metadata": {},
   "source": [
    "## Hypothesis Testing Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c638a0f7-3143-4458-9d1c-fd4228a75108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'lot_frontage', 'lot_area', 'overall_qual', 'overall_cond',\n",
       "       'mas_vnr_area', 'bsmtfin_sf_1', 'bsmtfin_sf_2', 'bsmt_unf_sf',\n",
       "       'total_bsmt_sf', '1st_flr_sf', '2nd_flr_sf', 'low_qual_fin_sf',\n",
       "       'gr_liv_area', 'garage_area', 'wood_deck_sf', 'open_porch_sf',\n",
       "       'pool_area', 'saleprice', 'exter_qual', 'exter_cond', 'bsmt_qual',\n",
       "       'bsmt_cond', 'heating_qc', 'kitchen_qual', 'fireplace_qu',\n",
       "       'garage_qual', 'garage_cond'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_hyp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac2c54-da63-4fe5-91be-f3715d54695d",
   "metadata": {},
   "source": [
    "Using our EDA and Visualizations, let's create better defined models for our hypothesis testing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a915cba-c71f-4915-a8c4-8796f9bfe0ba",
   "metadata": {},
   "source": [
    "---\n",
    "For our Model with More Quality/Condition Features than SF Features, will contain:<br>\n",
    "Quality/Condition: `overall_qual`, `overall_cond`, `kitchen_qual`, `heating_qc`, `fireplace_qu`, `bsmt_qual`<br>\n",
    "Squarefeet: `wood_deck_sf`,`lot_area`,`lot_frontage`,`mas_vnr_area`<br>\n",
    "\n",
    "These features were selected by examining the EDA as well as trying to reduce the multicollinearity we had in the original model. Each numerical feature that was selected above had both a positive correlation with price and a VIF score of <5. Hoping this allows us to finish both LassoCV and ElasticNetCV<br>\n",
    "\n",
    "10 Features in Total, 6 Categorical, 4 Numerical\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f7a1f-6534-47fb-a101-93ca26d547b2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For our Model with less Quality/Condition Features than SF Features, will contain:<br>\n",
    "Quality/Condition: `overall_qual`, `overall_cond`,`heating_qc1`,`bsmt_qual`<br>\n",
    "Squarefeet: `wood_deck_sf`,`lot_area`,`lot_frontage`,`mas_vnr_area`,`garage_area`,`bsmtfin_sf_2` <br>\n",
    "\n",
    "These features were selected by examining the EDA as well as trying to reduce the multicollinearity we had in the original model. A slight different for one of the numerical features in this model is `bsmtfin_sf_2` whose VIF was much greater than 5, but not infinite. In an effort to make balanced models Numerical/Categorical wise, I needed to dip into higher VIF scoring SQFT features. Once again a hole that the initial hypothesis put us in. As to slimming down the categorical features, I chose to drop both `fireplace_qu` and `heating_qc` based on their distributions<br>\n",
    "\n",
    "10 Features in Total, 4 Categorical, 6 Numerical\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f47f09-3574-4daa-92a2-9df48647c605",
   "metadata": {},
   "source": [
    "Experiment:\n",
    "Now that we have both our models with opposite amounts of Numerical and Categorical features, we need to get our mean RMSE scores to test our Null and Experimental Hypothesis.\n",
    "- Each Model will be run 3 different times using 3 different random states (1,42,777).\n",
    "- Each Model will attempt to run a Multi Linear Regression Model, a RidgeCV Model, and an ElasticNetCv Model\n",
    "- After each model run, scores will be collected across model types, have their average taken, and test our significant factor\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47ea8c13-5db9-4397-ac8d-846057bf9ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'lot_frontage', 'lot_area', 'overall_qual', 'overall_cond',\n",
       "       'mas_vnr_area', 'bsmtfin_sf_1', 'bsmtfin_sf_2', 'bsmt_unf_sf',\n",
       "       'total_bsmt_sf', '1st_flr_sf', '2nd_flr_sf', 'low_qual_fin_sf',\n",
       "       'gr_liv_area', 'garage_area', 'wood_deck_sf', 'open_porch_sf',\n",
       "       'pool_area', 'saleprice', 'exter_qual', 'exter_cond', 'bsmt_qual',\n",
       "       'bsmt_cond', 'heating_qc', 'kitchen_qual', 'fireplace_qu',\n",
       "       'garage_qual', 'garage_cond'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_hyp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d09ff23-d5e4-4f24-a229-4cf9e7a26424",
   "metadata": {},
   "source": [
    "# Model with More Qual/Cond Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b2323-e4dc-4225-b6ad-545688e1c551",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76dc555f-8982-40b0-9682-3bca7534b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_train = df_train_hyp.drop(columns=['bsmtfin_sf_1', 'bsmtfin_sf_2', 'bsmt_unf_sf','total_bsmt_sf',\n",
    "                                        '1st_flr_sf', '2nd_flr_sf', 'low_qual_fin_sf','gr_liv_area',\n",
    "                                        'garage_area','open_porch_sf','pool_area','exter_qual',\n",
    "                                       'exter_cond','bsmt_cond','garage_qual','garage_cond'])\n",
    "\n",
    "hypo_test = df_test_hyp.drop(columns=['bsmtfin_sf_1', 'bsmtfin_sf_2', 'bsmt_unf_sf','total_bsmt_sf',\n",
    "                                        '1st_flr_sf', '2nd_flr_sf', 'low_qual_fin_sf','gr_liv_area',\n",
    "                                        'garage_area','open_porch_sf','pool_area','exter_qual',\n",
    "                                       'exter_cond','bsmt_cond','garage_qual','garage_cond'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ad833c1-2d19-490e-b744-9b6c2ead091d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2051, 12), (878, 11))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo_train.shape, hypo_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9757abe7-9233-4d28-ae15-d20fcbf13a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dfs into their numerical and object forms for OHE\n",
    "hypo_train_num = hypo_train.select_dtypes('number')\n",
    "hypo_train_obj = hypo_train.select_dtypes('object')\n",
    "hypo_test_num = hypo_test.select_dtypes('number')\n",
    "hypo_test_obj = hypo_test.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b6de147-7b8a-4751-8d0d-50d990ba8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Transform Train Set\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    hypo_train_obj = ohe.fit_transform(hypo_train_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05bdee5b-d403-4185-a157-cb00e2fa96fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Test Set\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    hypo_test_obj = ohe.transform(hypo_test_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b40c7879-6ad3-4bb7-b6a7-5bc73911a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add index back to object for merge using saved indexes\n",
    "hypo_train_obj['id'] = train_id\n",
    "hypo_test_obj['id'] = test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43de1be7-fe41-45c3-bf22-58206119b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge respective dfs back together for \n",
    "hypo_ohe_train = hypo_train_num.merge(hypo_train_obj, how='left', on='id')\n",
    "hypo_ohe_test = hypo_test_num.merge(hypo_test_obj, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8406e7a-dcd2-43de-a6d4-05d6b7d23104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2051, 24), (878, 23))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Shapes after OHE\n",
    "hypo_ohe_train.shape,hypo_ohe_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7688f0c5-e83e-47f5-90bf-321b777241f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our X and Y\n",
    "X = hypo_ohe_train.drop(columns=['saleprice'])\n",
    "y = hypo_ohe_train['saleprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "03670be8-3f06-4acf-9b90-0e52fcb19f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Train Split, with different Random States to get mean RMSE for hypothesis\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7d42df5c-c9b6-4e16-97e7-be35f1b0928e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1538, 23), (513, 23), (1538,), (513,))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129ce4f-1fa9-4e20-8f00-3d82d557b41e",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f38e65-847e-485a-b9c5-021e3d005c66",
   "metadata": {},
   "source": [
    "#### Poly - combine variables on an interaction basis (a*b not a**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "175f1c5b-96aa-48ee-8809-f14d12ee1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly = poly.fit_transform(X_train.drop(columns=['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b373fe3d-f5c5-4d9e-8c69-271008c3d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_poly = poly.transform(X_test.drop(columns=['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "16b282ef-c1ce-454b-a74b-f5d478c0e47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1538, 253), (513, 253))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_poly.shape, X_test_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa701b-b7d2-4cf2-976e-20f964f15185",
   "metadata": {},
   "source": [
    "#### StandardScaler - Adjust all numerical features to the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fed6e83a-ee3f-4f34-8670-91a5136a9964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss = ss.fit_transform(X_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a5cf73c1-8f32-4ad1-8768-9ec1c977292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ss = ss.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ea17a-fd7f-41f4-a73e-377fc856afc6",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a418c-67ed-46ce-98bc-2e47d14920d5",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e016a9d6-1778-4000-8d8c-b4f95c4ee76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00018676221445179664"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_1 = [y_train.mean()]*len(y_test)\n",
    "r2_score(y_test, base_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72601475-42cd-48f7-af17-e4c1166681cc",
   "metadata": {},
   "source": [
    "Unbelievably our Base Model for our better fit model is even worse than it was when we used all features including features that had 'inf' multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef8556-fec5-4ba6-bfea-497785d0db5b",
   "metadata": {},
   "source": [
    "### Multi Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "726efa89-229c-4052-bf3f-fa4d6bb1908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "37e0e87f-15bd-4ab3-865b-b7b8168d9061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.fit(X_train_ss, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21922b4-1c49-4884-8ffa-951da74ad760",
   "metadata": {},
   "source": [
    "Calculate R2 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "61bd89ce-a6f7-4249-853f-2c6d6bd6ffab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8663915830139093"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.score(X_train_ss, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "54d855e5-9892-4c1b-ae11-bda62cb2ce90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.455706694072568e+22"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.score(X_test_ss, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eccf058-d283-4096-b329-d5a9ada35229",
   "metadata": {},
   "source": [
    "Calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b024606b-a491-4ecb-8d06-0aa544bcb081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28889.251970539026"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, mlr.predict(X_train_ss), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8bcee663-22c0-4260-91d4-5d2a7b1c3e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.484248680623979e+16"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, mlr.predict(X_test_ss), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c013f91-5c4f-4c43-8fa3-f98fff6ef318",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Observations:\n",
    "- #### our better fit model with more qual/cond performed slightly better than our combined model, only slightly in that our test RMSE is positive and not negative\n",
    "- #### our model continues to be overfit to our training data with less features and a much higher variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf941d-e6e6-4754-a336-66af9c2314d0",
   "metadata": {},
   "source": [
    "### Ridge CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b1613645-a598-4421-89ac-332ab299f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-10, 5, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ad0d25bd-a8b5-46d9-8dcc-ac06ec937e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_cv = RidgeCV(alphas=alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c9a5418e-9826-4be8-8e61-8cdca86b0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_cv.fit(X_train_ss, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a73e6fc9-3a6d-4a30-a993-a6483821c0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.619567705688056"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Alpha\n",
    "rg_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "33aae905-b810-4c66-8274-01c317448208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training r2: 0.8549186916703796\n",
      "validation r2: 0.7865731059575924\n",
      "cross val score: 0.7919776689512423\n",
      "\n",
      "training RMSE: 30104.063352292193\n",
      "validation RMSE: 36886.10570831829\n",
      "\n",
      "CPU times: user 1.78 s, sys: 439 ms, total: 2.22 s\n",
      "Wall time: 247 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"\"\"\n",
    "training r2: {rg_cv.score(X_train_ss, y_train)}\n",
    "validation r2: {rg_cv.score(X_test_ss, y_test)}\n",
    "cross val score: {cross_val_score(RidgeCV(alphas = rg_cv.alpha_), X_train_ss, y_train).mean()}\n",
    "\n",
    "training RMSE: {mean_squared_error(y_train, rg_cv.predict(X_train_ss), squared=False)}\n",
    "validation RMSE: {mean_squared_error(y_test, rg_cv.predict(X_test_ss), squared=False)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c09ac8-5a09-4cc5-804d-5a4e609e3033",
   "metadata": {},
   "source": [
    "Scores for Random_State = 1\n",
    "- training r2: 0.8556630430614536\n",
    "- validation r2: 0.8080414008572958\n",
    "- cross val score: 0.7741491661321669\n",
    "- training RMSE: 29673.485338501614\n",
    "- validation RMSE: 36165.97803392914\n",
    "\n",
    "Scores for Random State = 42\n",
    "- training r2: 0.8494395076424457\n",
    "- validation r2: 0.825969205544636\n",
    "- cross val score: 0.7912082145042719\n",
    "- training RMSE: 30858.10880892831\n",
    "- validation RMSE: 32688.734784197306\n",
    "\n",
    "Scores for Random State = 777\n",
    "- training r2: 0.8549186916703796\n",
    "- validation r2: 0.7865731059575924\n",
    "- cross val score: 0.7919776689512423\n",
    "- training RMSE: 30104.063352292193\n",
    "- validation RMSE: 36886.10570831829"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faaf88f-6f71-4228-9b7a-b56fe9be053a",
   "metadata": {},
   "source": [
    "### ElasticNetCv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d6cf4b-00bb-4ae3-bd0c-adbcc2085549",
   "metadata": {},
   "source": [
    "Train ENCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fcc4e51f-7f33-496b-9dae-03ecd8e4678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    enet_cv.fit(X_train_ss, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c30c0-622a-4a6f-9aa9-a3cb62857396",
   "metadata": {},
   "source": [
    "Find Best Alpha for ENCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "20ab7a13-8d1f-4a03-9c8b-551bdeadaab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04659525668664668"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4530f45d-853c-4b08-9bc6-fe9f5a0f3cd4",
   "metadata": {},
   "source": [
    "Calculate Scores for ENCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ff7f25b1-e273-485d-8805-0dce893febb3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 447053992711.9963, tolerance: 628811481.9287658\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 423759656836.5848, tolerance: 635579495.8964632\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 453080231368.94666, tolerance: 630427561.1434635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 486502367096.37036, tolerance: 646969492.1484877\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 446915201768.9233, tolerance: 617539356.6888041\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 462791028103.26746, tolerance: 593850959.2785975\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 360725140202.44885, tolerance: 583333082.4427854\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 436504581520.5603, tolerance: 589522425.9547135\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 442672383331.563, tolerance: 605959924.1703879\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 419233931927.9304, tolerance: 575887009.0067701\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 433506540918.61273, tolerance: 595585902.0140668\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 439226355597.854, tolerance: 628717097.7603459\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 389255888155.2693, tolerance: 605738006.2254926\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 463071587005.71533, tolerance: 617298775.7063365\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 420547590680.7664, tolerance: 593013258.3437479\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 415432120564.3345, tolerance: 611091329.2826359\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427447629445.4494, tolerance: 609570764.9106168\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 449526421341.9273, tolerance: 644385450.1606121\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 413229080600.3228, tolerance: 606310422.1724052\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 473065970958.30035, tolerance: 633573862.84646\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 404917000966.7756, tolerance: 610697191.5054283\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427604460544.848, tolerance: 613740522.8220892\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 451436835988.6867, tolerance: 617834350.9350771\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 443888280914.7605, tolerance: 624039889.1644443\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 455807572903.7282, tolerance: 646923951.5775459\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        training r2: 0.8535615841399949\n",
      "        validation r2: 0.7863989676759269\n",
      "        cross val score: 0.7893952765027602\n",
      "\n",
      "        training RMSE: 30244.534087147065\n",
      "        validation RMSE: 36901.15061026141\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    print(f\"\"\"\n",
    "        training r2: {enet_cv.score(X_train_ss, y_train)}\n",
    "        validation r2: {enet_cv.score(X_test_ss, y_test)}\n",
    "        cross val score: {cross_val_score(ElasticNetCV(alphas = [enet_cv.alpha_], n_jobs=-1), X_train_ss, y_train).mean()}\n",
    "\n",
    "        training RMSE: {mean_squared_error(y_train, enet_cv.predict(X_train_ss), squared=False)}\n",
    "        validation RMSE: {mean_squared_error(y_test, enet_cv.predict(X_test_ss), squared=False)}\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c15ed3-7e70-4329-881a-5fc5a6f11a5a",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- #### Initial Observation, with this more feature refined model we were able to actually complete the ElasticNetCV easily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebff7d0-d57f-4473-b101-45bef75443dd",
   "metadata": {},
   "source": [
    "ElasticNetCV\n",
    "Scores for Random_State = 1\n",
    "- training r2: 0.8542594092811929\n",
    "- validation r2: 0.8084967062962131\n",
    "- cross val score: 0.7722727880825254\n",
    "- training RMSE: 29817.4191462451\n",
    "- validation RMSE: 36123.06163838709<br>\n",
    "\n",
    "Scores for Random State = 42\n",
    "- training r2: 0.8501690762582578\n",
    "- validation r2: 0.8259373141311357\n",
    "- cross val score: 0.7909998105104303\n",
    "- training RMSE: 30783.253690865084\n",
    "- validation RMSE: 32691.729777715453\n",
    "\n",
    "Scores for Random State = 777\n",
    "- training r2: 0.8535615841399949\n",
    "- validation r2: 0.7863989676759269\n",
    "- cross val score: 0.7893952765027602\n",
    "- training RMSE: 30244.534087147065\n",
    "- validation RMSE: 36901.15061026141"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52be0e0d-995b-41a9-afe4-2800ed6347bf",
   "metadata": {},
   "source": [
    "### Model Final Observations and Analysis\n",
    "\n",
    "- #### Overall my model with More Qual/Cond Features remained to be overfit to the training data, just as the initial model with all features performed. \n",
    "- #### The models r2 scores stay in about the same range of each other across the RidgeCV and ElasticNetCV models, but as above with a trending overfit to the training set.\n",
    "- #### Across the different Random State changes, the Ridge CV and ElasticNetCV models performed similarly, keep a a range of 2k - 7k difference between training and validation RMSE\n",
    "- #### To Improve this model in a later project, we should look to use Ordinal Encoder to help delineate the value of the various ordinal series in the Qual/Cond Features.\n",
    "- #### As of this moment I think the null hypothesis will prevail, unless the Next Model with Less Qual/Cond Features performs even worse than this model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d275600b-001c-4ab1-8975-5f6ce5df871b",
   "metadata": {},
   "source": [
    "# Model with Less Qual/Cond Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517b7385-29ac-47ce-84c1-6aa3a8c4e655",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e4f96947-d254-48cc-888a-7b6a9a600c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo1_train = df_train_hyp.drop(columns=['bsmtfin_sf_1','bsmt_unf_sf','total_bsmt_sf','1st_flr_sf',\n",
    "                                        '2nd_flr_sf', 'low_qual_fin_sf','gr_liv_area','open_porch_sf',\n",
    "                                        'pool_area','exter_qual','exter_cond','bsmt_cond',\n",
    "                                        'garage_qual','garage_cond','fireplace_qu','kitchen_qual'])\n",
    "\n",
    "hypo1_test = df_test_hyp.drop(columns=['bsmtfin_sf_1','bsmt_unf_sf','total_bsmt_sf','1st_flr_sf',\n",
    "                                        '2nd_flr_sf', 'low_qual_fin_sf','gr_liv_area','open_porch_sf',\n",
    "                                        'pool_area','exter_qual','exter_cond','bsmt_cond',\n",
    "                                        'garage_qual','garage_cond','fireplace_qu','kitchen_qual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ef41a8ef-dc51-47be-963b-ed33253c89fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2051, 12), (878, 11))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo_train.shape, hypo_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0b39fcd6-fea2-4538-942c-a0948bb27651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dfs into their numerical and object forms for OHE\n",
    "hypo1_train_num = hypo1_train.select_dtypes('number')\n",
    "hypo1_train_obj = hypo1_train.select_dtypes('object')\n",
    "hypo1_test_num = hypo1_test.select_dtypes('number')\n",
    "hypo1_test_obj = hypo1_test.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3be2632c-be06-4a45-bdb4-5e1814bf1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Transform Train Set\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    hypo1_train_obj = ohe.fit_transform(hypo1_train_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e6a8a093-e4b1-44df-9abf-f94ba65a2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Test Set\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    hypo1_test_obj = ohe.transform(hypo1_test_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "adf09432-b3e9-48c1-ac6b-a5cd935ba46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add index back to object for merge using saved indexes\n",
    "hypo1_train_obj['id'] = train_id\n",
    "hypo1_test_obj['id'] = test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "dc372d3b-457f-4140-8034-80b9d1924328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge respective dfs back together for \n",
    "hypo1_ohe_train = hypo1_train_num.merge(hypo1_train_obj, how='left', on='id')\n",
    "hypo1_ohe_test = hypo1_test_num.merge(hypo1_test_obj, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "aa04a3e5-7f54-4f4c-88c3-ae57190ba783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2051, 18), (878, 17))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Shapes after OHE\n",
    "hypo1_ohe_train.shape,hypo1_ohe_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9c96e0b9-21ae-4137-b57e-354eb25784ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our X and Y\n",
    "X1 = hypo_ohe_train.drop(columns=['saleprice'])\n",
    "y1 = hypo_ohe_train['saleprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "cc47f0e5-82a8-493a-ace5-8f59b3646a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Train Split, with different Random States to get mean RMSE for hypothesis\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.25, random_state=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062471a9-2966-4854-a6dc-b0204df8c260",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10502bf6-2fba-422a-8986-eaf4c75215be",
   "metadata": {},
   "source": [
    "#### Poly - combine variables on an interaction basis (a*b not a**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "83282a49-d38d-499d-b2af-1953c21562de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train_poly = poly.fit_transform(X1_train.drop(columns=['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "d40c8e93-ae00-4065-871b-b615034e4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test_poly = poly.transform(X1_test.drop(columns=['id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a05c3-7a27-4707-a8bb-750f32659fd2",
   "metadata": {},
   "source": [
    "#### StandardScaler - Adjust all numerical features to the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c782c983-cbd2-4184-87b8-84dff8350acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train_ss = ss.fit_transform(X1_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "45a71d3e-10e1-40f1-ae41-fd479e3f261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test_ss = ss.transform(X1_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "af500366-b448-46ff-9dc5-f6babd25cdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1538, 253), (513, 253))"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train_ss.shape,X1_test_ss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c6507-cfe7-45ba-a72a-2896ce57332b",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662428e0-afe1-49e9-bbf7-f8e24b873693",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "83cc5765-2267-4af7-a54b-6c6e0ad1cb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00018676221445179664"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_1 = [y1_train.mean()]*len(y1_test)\n",
    "r2_score(y1_test, base_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "6fc46305-4997-4e99-a9ac-09b1bb2dd08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr1 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "7c305458-a226-42e6-99de-f17f5cf1ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr1.fit(X1_train_ss, y_train1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "585c46fe-06fb-4dac-937e-bc96c3992ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05649165250497434"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr1.score(X1_train_ss, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "410b011a-ddad-4b96-8b17-9f779cd28f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.286512045847645e+24"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr1.score(X1_test_ss, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "29590059-94b6-4b3e-bf00-32933dd90266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28889.251970539026"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y1_train, mlr.predict(X1_train_ss), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "2fbcf908-b35b-4596-8b97-d08bc0a15f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.484248680623979e+16"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y1_test, mlr.predict(X1_test_ss), squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3e6be-796b-44d4-bdda-8c1992ac9c69",
   "metadata": {},
   "source": [
    "Initial Observation(random_state=1): I think from this performance alone the model with more squarefeet fields is going to outperform the model with more qual/cond fields. The r2 scores are still reminiscent of being overfit to the training data, and while the RMSE is still extremely high, both of the values from the MLR model are the same length digits and both positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e96fc8-71fc-472c-8a68-4e4ef5877aa8",
   "metadata": {},
   "source": [
    "### Ridge CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "a614bb8d-062b-4bc9-9b80-c938d5f17449",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-10, 5, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "6c262fcc-e7f2-47e5-8409-147f4fb06a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_cv1 = RidgeCV(alphas=alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "c0e7d399-9632-4485-8ad4-9a97a6b9775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_cv1.fit(X1_train_ss, y1_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "448909e6-bb43-4fb9-b506-8e34b6417bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.619567705688056"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Alpha\n",
    "rg_cv1.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "2e1d6a0a-0d10-4774-baab-e7a9d08968aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training r2: 0.8549186916703796\n",
      "validation r2: 0.7865731059575924\n",
      "cross val score: 0.7919776689512423\n",
      "training RMSE: 30104.063352292193\n",
      "validation RMSE: 36886.10570831829\n",
      "\n",
      "CPU times: user 1.79 s, sys: 366 ms, total: 2.15 s\n",
      "Wall time: 240 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"\"\"\n",
    "training r2: {rg_cv1.score(X1_train_ss, y1_train)}\n",
    "validation r2: {rg_cv1.score(X1_test_ss, y1_test)}\n",
    "cross val score: {cross_val_score(RidgeCV(alphas = rg_cv1.alpha_), X1_train_ss, y1_train).mean()}\n",
    "training RMSE: {mean_squared_error(y1_train, rg_cv1.predict(X1_train_ss), squared=False)}\n",
    "validation RMSE: {mean_squared_error(y1_test, rg_cv1.predict(X1_test_ss), squared=False)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05194b68-0640-4ea5-882c-fd3af340547e",
   "metadata": {},
   "source": [
    "Scores for Random_State = 1\n",
    "- training r2: 0.8556630430614536\n",
    "- validation r2: 0.8080414008572958\n",
    "- cross val score: 0.7741491661321669\n",
    "- training RMSE: 29673.485338501614\n",
    "- validation RMSE: 36165.97803392914\n",
    "\n",
    "Scores for Random State = 42\n",
    "- training r2: 0.8494395076424457\n",
    "- validation r2: 0.825969205544636\n",
    "- cross val score: 0.7912082145042719\n",
    "- training RMSE: 30858.10880892831\n",
    "- validation RMSE: 32688.734784197306\n",
    "\n",
    "Scores for Random State = 777\n",
    "- training r2: 0.8549186916703796\n",
    "- validation r2: 0.7865731059575924\n",
    "- cross val score: 0.7919776689512423\n",
    "- training RMSE: 30104.063352292193\n",
    "- validation RMSE: 36886.10570831829"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b9b0f6-1a8d-45a9-8944-12b88178c2d7",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- #### Both of the below observations are incorrect, after scanning my code for errors, I found that i had not changed some of the test variables correctly. After fixing and rerunning the code, both models are performing exactly the same.\n",
    "    - #### My initial observation after seeing the mlr model perform better on more square feet variables was incorrect, the model with more Qual/Cond Features is definitely outperforming the model with more SQFT Variables\n",
    "    - #### What I find interesting is the r2 score ranges are pretty similar, but the RMSE ranges are astronomically different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d4f82-add3-489d-b0ea-5a3839b99061",
   "metadata": {},
   "source": [
    "### ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "ccaa26c5-ad03-4f57-84da-4f5a24ab083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    enet_cv1.fit(X1_train_ss, y1_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "5db51d63-e46a-4375-a026-28db6feb6f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04659525668664668"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv1.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "32253b0f-e946-441b-8e12-a439a2fec618",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 446915201768.9233, tolerance: 617539356.6888041\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 453080231368.94666, tolerance: 630427561.1434635\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 447053992711.9963, tolerance: 628811481.9287658\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 423759656836.5848, tolerance: 635579495.8964632\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 486502367096.37036, tolerance: 646969492.1484877\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 436504581520.5603, tolerance: 589522425.9547135\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 442672383331.563, tolerance: 605959924.1703879\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 419233931927.9304, tolerance: 575887009.0067701\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 360725140202.44885, tolerance: 583333082.4427854\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 462791028103.26746, tolerance: 593850959.2785975\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 420547590680.7664, tolerance: 593013258.3437479\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 433506540918.61273, tolerance: 595585902.0140668\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 439226355597.854, tolerance: 628717097.7603459\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 389255888155.2693, tolerance: 605738006.2254926\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 463071587005.71533, tolerance: 617298775.7063365\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 449526421341.9273, tolerance: 644385450.1606121\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427447629445.4494, tolerance: 609570764.9106168\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 415432120564.3345, tolerance: 611091329.2826359\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 413229080600.3228, tolerance: 606310422.1724052\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 473065970958.30035, tolerance: 633573862.84646\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 404917000966.7756, tolerance: 610697191.5054283\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 455807572903.7282, tolerance: 646923951.5775459\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427604460544.848, tolerance: 613740522.8220892\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 451436835988.6867, tolerance: 617834350.9350771\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/christopherjoyce/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 443888280914.7605, tolerance: 624039889.1644443\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        training r2: 0.8535615841399949\n",
      "        validation r2: 0.7863989676759269\n",
      "        cross val score: 0.7893952765027602\n",
      "        training RMSE: 30244.534087147065\n",
      "        validation RMSE: 36901.15061026141\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    print(f\"\"\"\n",
    "        training r2: {enet_cv1.score(X1_train_ss, y1_train)}\n",
    "        validation r2: {enet_cv1.score(X1_test_ss, y1_test)}\n",
    "        cross val score: {cross_val_score(ElasticNetCV(alphas = [enet_cv1.alpha_], n_jobs=-1), X1_train_ss, y1_train).mean()}\n",
    "        training RMSE: {mean_squared_error(y1_train, enet_cv1.predict(X1_train_ss), squared=False)}\n",
    "        validation RMSE: {mean_squared_error(y1_test, enet_cv1.predict(X1_test_ss), squared=False)}\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7013fcb6-be68-41b6-a39d-e7bc93ecade5",
   "metadata": {},
   "source": [
    "ElasticNetCV\n",
    "Scores for Random_State = 1\n",
    "- training r2: 0.8542594092811929\n",
    "- validation r2: 0.8084967062962131\n",
    "- cross val score: 0.7722727880825254\n",
    "- training RMSE: 29817.4191462451\n",
    "- validation RMSE: 36123.06163838709\n",
    "\n",
    "Scores for Random State = 42\n",
    "- training r2: 0.8501690762582578\n",
    "- validation r2: 0.8259373141311357\n",
    "- cross val score: 0.7909998105104303\n",
    "- training RMSE: 30783.253690865084\n",
    "- validation RMSE: 32691.729777715453\n",
    "\n",
    "Scores for Random State = 777\n",
    "- training r2: 0.8535615841399949\n",
    "- validation r2: 0.7863989676759269\n",
    "- cross val score: 0.7893952765027602\n",
    "- training RMSE: 30244.534087147065\n",
    "- validation RMSE: 36901.15061026141\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb4517f-485e-409b-9cec-c26c47d6a389",
   "metadata": {},
   "source": [
    "## Modeling Insights and Defense:\n",
    "- #### What I learned from this hypothesis and exercise is the importance of taking care with how you choose to manipulate the data. In this instance I chose to impute Median for Numerical and Mode for Categorical features. Even further I only chose to One Hot Encode rather than trying to continue to figure out Ordinal Encoder which I believe would have benefited the Qual/Condition Features greatly.\n",
    "- #### Both versions of the model performed, at some points (look at the scores..) exactly the same. I can't with much confidence support either model as they performed similarly.\n",
    "- #### Something I had a hard time combatting in this model and the models I built for the Kaggle competition was the bias of a given data set. Finding the right balance between bias and variance, more or less features seemed to be a delicate balance because my scores more or less stayed consistent no matter the action taken.\n",
    "- #### A mistake I caught which explains why the ElasticNetCV was performing similarly to the ridge was the l1_ratio field. I kept the values closer to Zero which balances the ENCV model to act more like a Ridge than a Lasso model. Next time I pick up this project I will look to better balance the l1_ratio to include the LassoCV side of the model.\n",
    "- #### The final lesson is to not be so strict on what you consider certain categories of features re what constitutes a quality/condition feature and what does not. After drilling further into the data dictionary supplied by Kaggle, I noticed that Basement Qual isnt actually what I thought it meant; it is related to the height of the basement ceiling and not actually the quality of the basement itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4939d8-75ba-4d4d-aa37-4327d72a01eb",
   "metadata": {},
   "source": [
    "# Hypothesis Testing and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861cd489-4640-45fd-8556-8c621ca93fec",
   "metadata": {},
   "source": [
    "Model with more Qual/Cond Features RidgeCV & ElasticNetCV mean RMSE across the three trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f521f5dc-e219-4e48-8660-372a513e7f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ridge_cv_rmse_mean = (29673.49+30858.11+30104.06)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "136930dc-fe95-46cc-8e1b-7f270ab1a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ridge_cv_rmse_mean = (36165.98+32688.73+36886.11)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "74fd4187-1c4f-4245-91f8-a8c3a40f5cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encv_rmse_mean = (29817.41+30783.25+30244.53)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "5d192f56-897d-4e21-b884-6cf9542605f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encv_rmse_mean = (36123+32691.73+36901.15)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce3f90a-0784-4526-b9ad-43ba3c556fbd",
   "metadata": {},
   "source": [
    "Model with less Qual/Cond Features RidgeCV & ElasticNetCV mean RMSE across the three trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "41bed41b-fdd2-4bf3-8844-51835768ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ridge_cv_rmse_mean1 = (29673.5+30858.11+30104.06)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "f76b2b82-10ae-4a74-946b-32596a4f4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ridge_cv_rmse_mean1 = (36165.97+32688.73+36886.11)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "3f2ffedb-ed60-4f15-8b10-c051d7216d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encv_rmse_mean1 = (29817.42+30783.25+30244.53)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "145ddb1f-85a8-48f6-8c11-b0e8ee2a64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encv_rmse_mean1 = (36123.06+32691.73+36901.15)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba57d9fc-e7ac-4040-a241-655a7a19ab82",
   "metadata": {},
   "source": [
    "Does the Null Hypothesis hold? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "361bca01-fabd-4e4f-b93c-a6464b5ef006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.003333333330374444"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ridge_cv_rmse_mean-train_ridge_cv_rmse_mean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "68570ff6-ed20-42de-bea3-80dc91bc6bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0033333333340124227"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ridge_cv_rmse_mean-test_ridge_cv_rmse_mean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "5cc1025c-d7ff-4cb0-857d-6e28099d2def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0033333333340124227"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encv_rmse_mean-train_encv_rmse_mean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "c2d66a23-721e-4332-a1cd-4bbbc527991a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01999999999679858"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_encv_rmse_mean-test_encv_rmse_mean1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d710e65-7ee0-4432-b8b2-241437c4af64",
   "metadata": {},
   "source": [
    "# Hypothesis Conclusion Statement:<br>\n",
    "### Because none of the differences taken by mean RMSE scores were larger than our level of significance = 0.05, there is insufficient evidence to reject our null hypothesis. We do not have enough evidence to conclude that Quality and Condition Features are better predictors of sale price than Squarefeet based features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b9211-72a9-49e2-a8b1-a95bf42721bd",
   "metadata": {},
   "source": [
    "# Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2688443a-7154-4c9c-b68a-c936c696a450",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "- ### From the current iteration of the model and data, there is not ample enough evidence to suggest that Quality/Condition nor SquareFt Feature based fields are the best predictors of price.\n",
    "- ### Quality and Condition Features range further than just Features that reference quality or condition in their name.\n",
    "- ### Squarefeet based features are also not entirely reliable on predicting potential sale price points either. As seen in EDA and further the performance of the models, Squarefeet Features have a very high multicollinearity with other Squarefeet Features which ultimately creates more noise than it does highlight the signal.\n",
    "- ### Despite postive Linear relationships between individual Quality,Condition,Squarefeet features and Sale Price, more features need to be included in order to accurately predict sale prices that better tie the entire picture together, potentially such as numbers of category rooms (baths, bedrooms, etc.) as well as adding features that detail home/bldg style."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff99dfb-09d2-4fe5-b4d7-6a414f8c8668",
   "metadata": {},
   "source": [
    "## Recommendations:\n",
    "- ### Fund another round of analysis on the data to take lessons learned and reapply to better understand the data and create a model that is less restrictive of features it includes.\n",
    "- ### When creating future models that predict price, ensure that the parameters set in cross validation models don't test models in a similar fasion.\n",
    "- ### Continue to focus on features that represent non-depcreciative value such as Squarefeet as they tend to have strong positive correlations with price.\n",
    "- ### When considering Quality/Condition Features, focus on instances of Heating quality and basement height as they are more evenly distributed than their peer features such as Garage Quality, Kitchen Quality, and Fireplace quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3e398-2563-474e-ab81-8b3012a0d706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
